/*
 * speedy-vision.js
 * GPU-accelerated Computer Vision for JavaScript
 * Copyright 2020-2021 Alexandre Martins <alemartf(at)gmail.com>
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 * harris.glsl
 * Harris corner detector
 */

/*
 * This is a GPU implementation of the Harris corner detector[1] with the
 * Shi-Tomasi corner response[2], adapted for working on multiple scales.
 *
 * References:
 *
 * [1] Harris, Christopher G.; Mike Stephens. "A combined corner and edge
 *     detector". Alvey Vision Conference. Vol. 15. No. 50. 1988.
 *
 * [2] Shi, J.; Tomasi, C. "Good features to track". 1994 Proceedings of
 *     IEEE Conference on Computer Vision and Pattern Recognition.
 */

@include "pyramids.glsl"
@include "float16.glsl"

#if !defined(WINDOW_SIZE)
#error Undefined WINDOW_SIZE
#endif
#define WINDOW_RADIUS ((WINDOW_SIZE - 1) / 2)

uniform sampler2D corners;
uniform sampler2D pyramid;
uniform sampler2D derivatives; // corresponding to lod
uniform float lod; // level-of-detail
uniform float lodStep; // 0 if not multiscale
uniform float gaussian[@WINDOW_SIZE@]; // 1D gaussian

// Gaussian kernel
//#define G1(x,y) 1.0
#define G1(x) gaussian[(x) + WINDOW_RADIUS]
#define G(x,y) (G1(x) * G1(y))

/*

Pyramid layers are generated by successive applications
of a 2D Gaussian g(1), i.e., a Gaussian of sigma^2 ~ 1.0.
If I(x,y) is the intensity value of an image at (x,y),
then we have, for each level-of-detail:

lod   intensity
---   ---------
 0    I(x,y)
 1    g(1) * I(x,y)
 2    g(1) * g(1) * I(x,y)
 3    g(1) * g(1) * g(1) * I(x,y)

 and so on, where * denotes convolution.

 The convolution of two Gaussians g(a) and g(b) generates[1]
 a third Gaussian of sigma^2 = a+b, i.e., g(a+b). Therefore,
 the intensity value at (x,y) for lod = t > 0 is g(t) * I(x,y).

 Let L(x,y,t) = g(t) * I(x,y) be the scale-space representation[2]
 of I. The scale-normalized Laplacian of L(x,y,t) is given by[3,4]:

 t \/^2 L = t (Lxx(x,y;t) + Lyy(x,y;t)) = t tr(H(L_t))

 where tr(H(L_t)) is trace of the Hessian of L(x,y;t) (fixed t)

 [1] Bromiley, Paul. "Products and convolutions of Gaussian probability density functions"
 [2] Lindeberg, Tony. "Scale selection" available at https://people.kth.se/~tony/papers/Lin14-ScSel-CompVisRefGuide.pdf
 [3] https://en.wikipedia.org/wiki/Blob_detection
 [4] https://en.wikipedia.org/wiki/Corner_detection

*/

/**
 * Compute the scale-normalized Laplacian of the thread pixel
 * at a specific level-of-detail
 * @param {float} lod
 * @returns {float}
 */
float laplacian(float lod)
{
    float pot = exp2(lod);

    // read nearby pixels
    float up = pyrPixelAtOffset(pyramid, lod, pot, ivec2(0,-1)).g;
    float down = pyrPixelAtOffset(pyramid, lod, pot, ivec2(0,-1)).g;
    float left = pyrPixelAtOffset(pyramid, lod, pot, ivec2(-1,0)).g;
    float right = pyrPixelAtOffset(pyramid, lod, pot, ivec2(1,0)).g;
    float center = pyrPixelAtOffset(pyramid, lod, pot, ivec2(0,0)).g;
    mat3 neighborhood = mat3(
        0, up, 0,
        left, center, right,
        0, down, 0
    );

    // compute the Laplacian
    const vec3 ones = vec3(1.0f);
    const mat3 kernel = -mat3(
        0,-1, 0,
       -1, 4,-1,
        0,-1, 0
    );

    mat3 lp = matrixCompMult(neighborhood, kernel);
    return dot(ones, vec3(
        dot(lp[0], ones),
        dot(lp[1], ones),
        dot(lp[2], ones)
    )) * (1.0f + lod);
}

/**
 * Compute a term of the autocorrelation matrix
 * @param {const int} ox x-offset from the thread pixel
 * @param {const int} oy y-offset from the thread pixel
 */
#define H(ox,oy) dpix = pixelAtShortOffset(derivatives, ivec2((ox),(oy))); \
                 df = (1.0f + lod) * decodePairOfFloat16(dpix); \
                 h += vec3(df.x * df.x, df.x * df.y, df.y * df.y) * G((ox),(oy))

/*

The output of this shader
is a corner response map

*/

void main()
{
    vec4 pixel = threadPixel(corners);
    vec4 dpix = vec4(0.0f);
    vec2 df = vec2(0.0f);
    vec3 h = vec3(0.0f);

    // Keep current pixel
    color = pixel;

    //
    // Compute Harris' autocorrelation matrix
    // over a small window
    //
    // H = [ a  b ]   <=>   h = (a, b, c)
    //     [ b  c ]
    //
    #if WINDOW_SIZE == 1
    H(0,0);
    #elif WINDOW_SIZE == 3
    H(-1,-1); H(0,-1); H(1,-1);
    H(-1,0); H(0,0); H(1,0);
    H(-1,1); H(0,1); H(1,1);
    #elif WINDOW_SIZE == 5
    H(-2,-2); H(-1,-2); H(0,-2); H(1,-2); H(2,-2);
    H(-2,-1); H(-1,-1); H(0,-1); H(1,-1); H(2,-1);
    H(-2,0); H(-1,0); H(0,0); H(1,0); H(2,0);
    H(-2,1); H(-1,1); H(0,1); H(1,1); H(2,1);
    H(-2,2); H(-1,2); H(0,2); H(1,2); H(2,2);
    #elif WINDOW_SIZE == 7
    H(-3,-3); H(-2,-3); H(-1,-3); H(0,-3); H(1,-3); H(2,-3); H(3,-3);
    H(-3,-2); H(-2,-2); H(-1,-2); H(0,-2); H(1,-2); H(2,-2); H(3,-2);
    H(-3,-1); H(-2,-1); H(-1,-1); H(0,-1); H(1,-1); H(2,-1); H(3,-1);
    H(-3,0); H(-2,0); H(-1,0); H(0,0); H(1,0); H(2,0); H(3,0);
    H(-3,1); H(-2,1); H(-1,1); H(0,1); H(1,1); H(2,1); H(3,1);
    H(-3,2); H(-2,2); H(-1,2); H(0,2); H(1,2); H(2,2); H(3,2);
    H(-3,3); H(-2,3); H(-1,3); H(0,3); H(1,3); H(2,3); H(3,3);
    #else
    #error Invalid WINDOW_SIZE
    #endif

    // compute corner response (Shi-Tomasi)
    float response = 0.5f * (h.x + h.z - sqrt((h.x - h.z) * (h.x - h.z) + 4.0f * h.y * h.y));

    // write the result it if the Laplacian response is higher than at the previous lod
    float currentScaleStrength = abs(laplacian(lod));
    float previousScaleStrength = (min(lod, lodStep) > 0.0f) ? abs(laplacian(lod - lodStep)) : 0.0f;
    float previousResponse = decodeFloat16(pixel.rb);

    vec3 result = vec3(encodeFloat16(response), encodeLod(lod));
    color.rba = (currentScaleStrength > previousScaleStrength || previousResponse == 0.0f) ? result : pixel.rba;
/*
    color.rba = response > previousResponse ? result : pixel.rba;
*/
}